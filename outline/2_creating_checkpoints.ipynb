{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document examines how to save and restore TensorFlow models built with Estimators. TensorFlow provides two model formats:\n",
    "\n",
    "> **checkpoints**, which is a format dependent on the code that created the model.\n",
    "\n",
    "> **SavedModel**, which is a format independent of the code that created the model.\n",
    "\n",
    "**This document focuses on checkpoints**. For details on SavedModel, see the Saving and Restoring chapter of the TensorFlow Programmer's Guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the iris training data and creating feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path : /home/sankaran/.keras/datasets/iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "# Create a local copy of the training set.\n",
    "train_path = tf.keras.utils.get_file(fname=TRAIN_URL.split('/')[-1],\n",
    "                                         origin=TRAIN_URL)\n",
    "print(\"Train path :\", train_path)\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "# Parse the local CSV file.\n",
    "train = pd.read_csv(filepath_or_buffer=train_path,\n",
    "                    names=CSV_COLUMN_NAMES,  # list of column names\n",
    "                    header=0  # ignore the first row of the CSV file.\n",
    "                    )\n",
    "\n",
    "train_features, train_label = train, train.pop('Species')\n",
    "\n",
    "my_feature_columns = []\n",
    "for key in train_features.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default checkpoint config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators automatically write the following to disk:\n",
    "\n",
    "> **checkpoints**, which are versions of the model created during training.\n",
    "\n",
    "> **event files**, which contain information that TensorBoard uses to create visualizations.\n",
    "\n",
    "To specify the top-level directory in which the Estimator stores its information, assign a value to the optional **model_dir** argument of any Estimator's constructor. If you don't specify model_dir in an Estimator's constructor, the Estimator writes checkpoint files to a temporary directory chosen by Python's **tempfile.mkdtemp** function. Eg,\n",
    "\n",
    "```python\n",
    "    print(classifier.model_dir)\n",
    "\n",
    "    Out : '/tmp/tmpc626k_qy'\n",
    "```\n",
    "\n",
    "**By default**, the Estimator saves checkpoints in the model_dir according to the following schedule:\n",
    "\n",
    "    Writes a checkpoint every 10 minutes (600 seconds).\n",
    "    Writes a checkpoint when the train method starts (first iteration) and completes (final iteration).\n",
    "    Retains only the 5 most recent checkpoints in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_tf_random_seed': None, '_session_config': None, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_service': None, '_save_checkpoints_steps': None, '_master': '', '_model_dir': 'models/iris', '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fef66346cf8>, '_log_step_count_steps': 100, '_is_chief': True, '_evaluation_master': ''}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris/model.ckpt-1003\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1004 into models/iris/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.22666949, step = 1003\n",
      "INFO:tensorflow:global_step/sec: 840.694\n",
      "INFO:tensorflow:loss = 0.7391975, step = 1103 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 1060.93\n",
      "INFO:tensorflow:loss = 0.39801908, step = 1203 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1083.5\n",
      "INFO:tensorflow:loss = 1.5360976, step = 1303 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1070.35\n",
      "INFO:tensorflow:loss = 0.25191778, step = 1403 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1060.94\n",
      "INFO:tensorflow:loss = 0.3736205, step = 1503 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1058.35\n",
      "INFO:tensorflow:loss = 0.076498024, step = 1603 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1095.61\n",
      "INFO:tensorflow:loss = 0.012479626, step = 1703 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1054.59\n",
      "INFO:tensorflow:loss = 0.14980444, step = 1803 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1028.62\n",
      "INFO:tensorflow:loss = 0.08977395, step = 1903 (0.097 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2003 into models/iris/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.10310379.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7fef66346be0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=my_feature_columns,\n",
    "        # Two hidden layers of 10 nodes each.\n",
    "        hidden_units=[10, 10],\n",
    "        # The model must choose between 3 classes.\n",
    "        n_classes=3,\n",
    "        model_dir='models/iris')\n",
    "\n",
    "import code.iris_data as iris_data\n",
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:iris_data.train_input_fn(train_features, train_label, 10),\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.ckpt-2003.data-00000-of-00001',\n",
       " 'events.out.tfevents.1520235075.sankaran-System-Product-Name',\n",
       " 'model.ckpt-1001.meta',\n",
       " 'events.out.tfevents.1520237587.sankaran-System-Product-Name',\n",
       " 'model.ckpt-1003.index',\n",
       " 'model.ckpt-2003.index',\n",
       " 'events.out.tfevents.1520238141.sankaran-System-Product-Name',\n",
       " 'model.ckpt-1002.data-00000-of-00001',\n",
       " 'events.out.tfevents.1520237708.sankaran-System-Product-Name',\n",
       " 'model.ckpt-1002.index',\n",
       " 'events.out.tfevents.1520238164.sankaran-System-Product-Name',\n",
       " 'eval',\n",
       " 'events.out.tfevents.1520237617.sankaran-System-Product-Name',\n",
       " 'model.ckpt-1002.meta',\n",
       " 'model.ckpt-1001.index',\n",
       " 'checkpoint',\n",
       " 'model.ckpt-1004.index',\n",
       " 'model.ckpt-2003.meta',\n",
       " 'model.ckpt-1003.data-00000-of-00001',\n",
       " 'graph.pbtxt',\n",
       " 'model.ckpt-1004.meta',\n",
       " 'model.ckpt-1004.data-00000-of-00001',\n",
       " 'model.ckpt-1003.meta',\n",
       " 'model.ckpt-1001.data-00000-of-00001']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"models/iris/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altering the default checkpoint config\n",
    "\n",
    "You may alter the default schedule by taking the following steps:\n",
    "\n",
    "    1) Create a RunConfig object that defines the desired schedule.\n",
    "    2) When instantiating the Estimator, pass that RunConfig object to the Estimator's config argument.\n",
    "    \n",
    "**tf.estimator.RunConfig**\n",
    "\n",
    "__init__(\n",
    "\n",
    "    model_dir=None,\n",
    "    tf_random_seed=None,\n",
    "    save_summary_steps=100,\n",
    "    save_checkpoints_steps=_USE_DEFAULT,\n",
    "    save_checkpoints_secs=_USE_DEFAULT,\n",
    "    session_config=None,\n",
    "    keep_checkpoint_max=5,\n",
    "    keep_checkpoint_every_n_hours=10000,\n",
    "    log_step_count_steps=100\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_id': 0, '_tf_random_seed': None, '_session_config': None, '_keep_checkpoint_max': 10, '_save_summary_steps': 100, '_service': None, '_save_checkpoints_steps': None, '_master': '', '_model_dir': 'models/iris', '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_task_type': 'worker', '_save_checkpoints_secs': 1200, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fef66346940>, '_log_step_count_steps': 100, '_is_chief': True, '_evaluation_master': ''}\n"
     ]
    }
   ],
   "source": [
    "my_checkpointing_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs = 20*60,  # Save checkpoints every 20 minutes.\n",
    "    keep_checkpoint_max = 10,       # Retain the 10 most recent checkpoints.\n",
    ")\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    hidden_units=[10, 10],\n",
    "    n_classes=3,\n",
    "    model_dir='models/iris',\n",
    "    config=my_checkpointing_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator automatically loads the latest checkpoint from **model_dir**. Thus, if you re-run this code 10 times with 1000 steps each, the model would have actually been trained for 10*1000 steps. \n",
    "\n",
    "If **model_dir** is **not specified**, automatic restoration will not happen.\n",
    "\n",
    "**IMPORTANT** : Whenever you change the network architecture (or restart training), you have to change (or clear) model_dir. Otherwise, you will encounter a mis-match\n",
    "\n",
    "#### Eg, \n",
    "\n",
    "I changed the network-arch without changing the model dir, and got the following error. As you can see, the **estimator class** first calls **model_fn** before training, which restores the latest parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_id': 0, '_tf_random_seed': None, '_session_config': None, '_keep_checkpoint_max': 10, '_save_summary_steps': 100, '_service': None, '_save_checkpoints_steps': None, '_master': '', '_model_dir': 'models/iris', '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_task_type': 'worker', '_save_checkpoints_secs': 1200, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fef658ad7b8>, '_log_step_count_steps': 100, '_is_chief': True, '_evaluation_master': ''}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris/model.ckpt-1003\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "tensor_name = dnn/hiddenlayer_1/bias; shape in shape_and_slice spec [11] does not match the shape stored in checkpoint: [10]\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/ioloop.py\", line 160, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-b88bc9d75048>\", line 15, in <module>\n    steps=1000)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/estimator/estimator.py\", line 899, in _train_model\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 384, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 795, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 518, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 981, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 986, in _create_session\n    return self._sess_creator.create_session()\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 675, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 437, in create_session\n    self._scaffold.finalize()\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 214, in finalize\n    self._saver.build()\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 790, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 502, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 449, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 847, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1469, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 3259, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): tensor_name = dnn/hiddenlayer_1/bias; shape in shape_and_slice spec [11] does not match the shape stored in checkpoint: [10]\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: tensor_name = dnn/hiddenlayer_1/bias; shape in shape_and_slice spec [11] does not match the shape stored in checkpoint: [10]\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b88bc9d75048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m classifier.train(\n\u001b[1;32m     14\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miris_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     steps=1000)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    897\u001b[0m           \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m           log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mall_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m   return MonitoredSession(session_creator=session_creator, hooks=all_hooks,\n\u001b[0;32m--> 384\u001b[0;31m                           stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    793\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    794\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    516\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \"\"\"\n\u001b[1;32m    980\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         config=config)\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# Loads the checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover_last_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_model_checkpoint_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1755\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1756\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: tensor_name = dnn/hiddenlayer_1/bias; shape in shape_and_slice spec [11] does not match the shape stored in checkpoint: [10]\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/ioloop.py\", line 160, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.4/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-b88bc9d75048>\", line 15, in <module>\n    steps=1000)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/estimator/estimator.py\", line 899, in _train_model\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 384, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 795, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 518, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 981, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 986, in _create_session\n    return self._sess_creator.create_session()\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 675, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 437, in create_session\n    self._scaffold.finalize()\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/monitored_session.py\", line 214, in finalize\n    self._saver.build()\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 790, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 502, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 449, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/saver.py\", line 847, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1469, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 3259, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): tensor_name = dnn/hiddenlayer_1/bias; shape in shape_and_slice spec [11] does not match the shape stored in checkpoint: [10]\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "my_checkpointing_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs = 20*60,  # Save checkpoints every 20 minutes.\n",
    "    keep_checkpoint_max = 10,       # Retain the 10 most recent checkpoints.\n",
    ")\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    hidden_units=[10, 11],\n",
    "    n_classes=3,\n",
    "    model_dir='models/iris',\n",
    "    config=my_checkpointing_config)\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda:iris_data.train_input_fn(train_features, train_label, 10),\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
