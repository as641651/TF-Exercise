{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The general outline of many TensorFlow programs:\n",
    "\n",
    "    1) Import and parse the data sets.\n",
    "    2) Create feature columns to describe the data.\n",
    "    3) Select the type of model\n",
    "    4) Train the model.\n",
    "    5) Evaluate the model's effectiveness.\n",
    "    6) Let the trained model make predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)  Import and parsing\n",
    "\n",
    "Keras is an open-sourced machine learning library; tf.keras is a TensorFlow implementation of Keras. The premade_estimator.py program only accesses one tf.keras function; namely, the tf.keras.utils.get_file convenience function, which copies a remote CSV file to a local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a file from url and storing in cache\n",
    "\n",
    "**tf.keras.utils.get_file**\n",
    "\n",
    "**get_file**(fname, origin, untar=False, md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', extract=False, archive_format='auto', cache_dir=None) \n",
    "\n",
    "___\n",
    "    Downloads a file from a URL if it not already in the cache.\n",
    "    \n",
    "    By default the file at the url `origin` is downloaded to the\n",
    "    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n",
    "    and given the filename `fname`. The final location of a file\n",
    "    `example.txt` would therefore be `~/.keras/datasets/example.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train path : /home/sankaran/.keras/datasets/iris_training.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "# Create a local copy of the training set.\n",
    "train_path = tf.keras.utils.get_file(fname=TRAIN_URL.split('/')[-1],\n",
    "                                         origin=TRAIN_URL)\n",
    "print(\"Train path :\", train_path)\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "# Parse the local CSV file.\n",
    "train = pd.read_csv(filepath_or_buffer=train_path,\n",
    "                    names=CSV_COLUMN_NAMES,  # list of column names\n",
    "                    header=0  # ignore the first row of the CSV file.\n",
    "                    )\n",
    "train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Describe the data\n",
    "\n",
    "**a) Separate the independent and dependent variables**\n",
    "\n",
    "Assigns from **right to left**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # 1. Assign the DataFrame's labels (the right-most column) to train_label.\n",
    "    # 2. Delete (pop) the labels from the DataFrame.\n",
    "    # 3. Assign the remainder of the DataFrame to train_features\n",
    "    train_features, train_label = train, train.pop('Species')\n",
    "    train_features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Create feature columns** \n",
    "\n",
    "When you build an Estimator model, you pass it a list of feature columns that describes each of the features you want the model to use. The tf.feature_column module provides many options for representing data to the model.\n",
    "\n",
    "For Iris, the 4 raw features are numeric values, so we'll build a list of feature columns to tell the Estimator model to represent each of the four features as 32-bit floating-point values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature columns for all features.\n",
    "my_feature_columns = []\n",
    "for key in train_features.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Select model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify a model type, instantiate an **Estimator** class. TensorFlow provides two categories of Estimators:\n",
    "\n",
    "    1) pre-made Estimators, which someone else has already written for you.\n",
    "    2) custom Estimators, which you must code yourself, at least partially.\n",
    "    \n",
    "TensorFlow provides several pre-made classifier Estimators, including:\n",
    "\n",
    "    1) tf.estimator.DNNClassifier for deep models that perform multi-class classification.\n",
    "    2) tf.estimator.DNNLinearCombinedClassifier for wide & deep models.\n",
    "    3) tf.estimator.LinearClassifier for classifiers based on linear models.\n",
    "\n",
    "    \n",
    "Instantiating a tf.Estimator.DNNClassifier **creates a framework for learning the model**. It handles the details of initialization, logging, saving and restoring, and many other features so you can concentrate on your model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using pre-made estimator - DNNClassifier**\n",
    "\n",
    "_init__(\n",
    "\n",
    "    hidden_units,\n",
    "    feature_columns,\n",
    "    model_dir=None,\n",
    "    n_classes=2,\n",
    "    weight_column=None,\n",
    "    label_vocabulary=None,\n",
    "    optimizer='Adagrad',\n",
    "    activation_fn=tf.nn.relu,\n",
    "    dropout=None,\n",
    "    input_layer_partitioner=None,\n",
    "    config=None,\n",
    "    warm_start_from=None,\n",
    "    loss_reduction=losses.Reduction.SUM\n",
    ")\n",
    "\n",
    "> **hidden_units**: Iterable of number hidden units per layer. All layers are fully connected. Ex. [64, 32] means first layer has 64 nodes and second one has 32.\n",
    "\n",
    "> **feature_columns** : An iterable containing all the feature columns used by the model. All items in the set should be instances of classes derived from _FeatureColumn.\n",
    "\n",
    "> **optimizer**: An instance of tf.Optimizer used to train the model. **Defaults to Adagrad** optimizer.\n",
    "\n",
    "> **activation_fn**: Activation function applied to each layer. If None, will use **tf.nn.relu**.\n",
    "\n",
    "> **dropout**: When not None, the probability we will drop out a given coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpg61wvmwu\n",
      "INFO:tensorflow:Using config: {'_master': '', '_tf_random_seed': None, '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/tmpg61wvmwu', '_task_type': 'worker', '_session_config': None, '_is_chief': True, '_save_summary_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_keep_checkpoint_max': 5, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc2640963c8>, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_evaluation_master': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpg61wvmwu'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=my_feature_columns,\n",
    "        # Two hidden layers of 10 nodes each.\n",
    "        hidden_units=[10, 10],\n",
    "        # The model must choose between 3 classes.\n",
    "        n_classes=3)\n",
    "    classifier.model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Train the model\n",
    "\n",
    "Basically, we've wired a network but haven't yet let data flow through it. To train the neural network, call the Estimator object's train method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) create an input function**\n",
    "\n",
    "**Dataset** object is used as **input function** to Estimator models. An input function is a function that returns a **tf.data.Dataset** object which outputs the following two-element tuple:\n",
    "\n",
    "    1) features - A Python dictionary in which:\n",
    "        Each key is the name of a feature.\n",
    "        Each value is an array containing all of that feature's values.\n",
    "    2) label - An array containing the values of the label for every example.\n",
    "\n",
    "just to demonstrate the format of the input function, here's a simple implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels\n",
    "```\n",
    "\n",
    "Your input function may generate the features dictionary and label list any way you like. However, it is recommended using TensorFlow's Dataset API, which can parse and manage all sorts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({PetalWidth: (?,), SepalWidth: (?,), SepalLength: (?,), PetalLength: (?,)}, (?,)), types: ({PetalWidth: tf.float64, SepalWidth: tf.float64, SepalLength: tf.float64, PetalLength: tf.float64}, tf.int64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the inputs to a Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((dict(train_features), train_label))\n",
    "dataset = dataset.shuffle(1000).repeat().batch(10)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Call classifier.train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we wrap up our input_fn call in a lambda to capture the arguments while providing an input function that takes no arguments, as expected by the Estimator. The steps argument tells the method to stop training after a number of training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpg61wvmwu/model.ckpt.\n",
      "INFO:tensorflow:step = 0, loss = 17.946484\n",
      "INFO:tensorflow:global_step/sec: 833.627\n",
      "INFO:tensorflow:step = 100, loss = 2.6058917 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 1064.7\n",
      "INFO:tensorflow:step = 200, loss = 0.78486764 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1085.52\n",
      "INFO:tensorflow:step = 300, loss = 0.78320974 (0.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 1055.94\n",
      "INFO:tensorflow:step = 400, loss = 1.0279917 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1044.49\n",
      "INFO:tensorflow:step = 500, loss = 2.2164102 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1044.84\n",
      "INFO:tensorflow:step = 600, loss = 0.48744252 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 988.635\n",
      "INFO:tensorflow:step = 700, loss = 1.1422038 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1077.42\n",
      "INFO:tensorflow:step = 800, loss = 0.58211905 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1039.32\n",
      "INFO:tensorflow:step = 900, loss = 0.21635883 (0.096 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpg61wvmwu/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.07006411.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7fc2640c0668>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import code.iris_data as iris_data\n",
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:iris_data.train_input_fn(train_features, train_label, 10),\n",
    "    steps=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Evaluate\n",
    "\n",
    "Now that the model has been trained, we can get some statistics on its performance. The following code block evaluates the accuracy of the trained model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-05-08:20:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpg61wvmwu/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-05-08:20:17\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.93333334, average_loss = 0.06811817, global_step = 1000, loss = 0.06811817\n"
     ]
    }
   ],
   "source": [
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test_x, test_y = test, test.pop('Species')\n",
    "\n",
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(test_x, test_y,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.93333334,\n",
       " 'average_loss': 0.06811817,\n",
       " 'global_step': 1000,\n",
       " 'loss': 0.06811817}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Making predictions (inferring) from the trained model\n",
    "\n",
    "The predict method returns a Python iterable, yielding a dictionary of prediction results for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object predict at 0x7fc250c153f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(predict_x,None,\n",
    "                                            batch_size=1))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpg61wvmwu/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "dict_keys(['logits', 'class_ids', 'probabilities', 'classes'])\n",
      "dict_keys(['logits', 'class_ids', 'probabilities', 'classes'])\n",
      "dict_keys(['logits', 'class_ids', 'probabilities', 'classes'])\n"
     ]
    }
   ],
   "source": [
    "for p in predictions:\n",
    "   print(p.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpg61wvmwu/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"Setosa\" (99.8%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"Versicolor\" (99.5%), expected \"Versicolor\"\n",
      "\n",
      "Prediction is \"Virginica\" (87.8%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(iris_data.SPECIES[class_id],\n",
    "                          100 * probability, expec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
