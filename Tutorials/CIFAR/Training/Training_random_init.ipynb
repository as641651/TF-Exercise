{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tf(x):\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    with tf.Session(config=config) as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        out = sess.run(x)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "class FLAGS(object):\n",
    "    pass\n",
    "\n",
    "FLAGS.batch_size = 128\n",
    "FLAGS.data_dir = \"/home/sankaran/exercise/ML/TF-Exercise/Tutorials/CIFAR/cifar-10-batches-bin\"\n",
    "FLAGS.num_preprocess_threads = 16\n",
    "FLAGS.num_classes = 10\n",
    "FLAGS.dtype = tf.float32\n",
    "\n",
    "def distorted_inputs(data_dir, batch_size, distort=True):\n",
    "    \n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in range(1, 6)]\n",
    "    \n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames,seed=0)\n",
    "    \n",
    "    #Create FixedLenthRecord Reader with fixed bytes to read\n",
    "    record_bytes = 32*32*3+1 #32*32*3 image with 1 byte for label\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    \n",
    "    key, value = reader.read(filename_queue)\n",
    "    \n",
    "    ##Decode\n",
    "    decoded = tf.decode_raw(value, tf.uint8)\n",
    "    label = tf.strided_slice(decoded,[0],[1])\n",
    "    image = tf.strided_slice(decoded,[1],[record_bytes])\n",
    "    \n",
    "    \n",
    "    label = tf.cast(label,tf.int32)\n",
    "    label = tf.reshape(label,[1])\n",
    "    image = tf.reshape(image,[3,32,32])\n",
    "    image = tf.transpose(image,[1,2,0])\n",
    "    #image = tf.cast(image,tf.float32) ## DESTROYES IMAGE VIS\n",
    "    \n",
    "    ##PRE PROCESS\n",
    "    if(distort):\n",
    "        image = tf.random_crop(image, [24, 24, 3])\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_brightness(image,max_delta=0.4)\n",
    "        image = tf.image.random_contrast(image,lower=0.5,upper=1.8)\n",
    "    \n",
    "    image = tf.image.convert_image_dtype(image,dtype=FLAGS.dtype)\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                             min_fraction_of_examples_in_queue)\n",
    "    \n",
    "    images, label_batch = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=FLAGS.num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size,\n",
    "        min_after_dequeue=min_queue_examples,\n",
    "        seed=0)\n",
    "    \n",
    "    return [images,label_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "    \n",
    "    def weight_variable(shape,std=0.1,dtype=FLAGS.dtype):\n",
    "      initializer = tf.truncated_normal_initializer(stddev=std, dtype=dtype)\n",
    "      return tf.get_variable(\"Weights\",shape,initializer=initializer,dtype=dtype)\n",
    "\n",
    "    def bias_variable(shape,const=0.0,dtype=FLAGS.dtype):\n",
    "      initializer = tf.constant_initializer(const,dtype)\n",
    "      return tf.get_variable(\"biases\",shape,initializer=initializer,dtype=dtype)\n",
    "    \n",
    "    print(\"input : \", images)\n",
    "    \n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        W_conv1 = weight_variable([5, 5, 3, 64])\n",
    "        b_conv1 = bias_variable([64])\n",
    "\n",
    "        conv = tf.nn.conv2d(images,W_conv1,strides=[1,1,1,1],padding=\"SAME\")\n",
    "        h_conv1 = tf.nn.relu(conv + b_conv1)\n",
    "        \n",
    "        print(\"conv 1 : \",h_conv1)\n",
    "        \n",
    "    with tf.variable_scope(\"maxpool1\"):\n",
    "        h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1,3,3,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "        \n",
    "        print(\"pool 1 : \",h_pool1)\n",
    "        \n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        W_conv2 = weight_variable([5, 5, 64, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "\n",
    "        conv = tf.nn.conv2d(h_pool1,W_conv2,strides=[1,1,1,1],padding=\"SAME\")\n",
    "        h_conv2 = tf.nn.relu(conv + b_conv2)\n",
    "        \n",
    "        print(\"conv 2 : \",h_conv2)\n",
    "        \n",
    "    with tf.variable_scope(\"maxpool2\"):\n",
    "        h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1,3,3,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "        \n",
    "        print(\"pool 2 : \",h_pool2)\n",
    "        \n",
    "    with tf.variable_scope(\"Flatten\"):\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [FLAGS.batch_size, -1])\n",
    "        \n",
    "        print(\"flatten : \",h_pool2_flat)\n",
    "        \n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "        W_fc1 = weight_variable([h_pool2_flat.shape[1].value, 384])\n",
    "        b_fc1 = bias_variable([384])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        \n",
    "        print(\"fc1 : \",h_fc1)\n",
    "        \n",
    "    with tf.variable_scope(\"fc2\"):\n",
    "        W_fc2 = weight_variable([384, 192])\n",
    "        b_fc2 = bias_variable([192])\n",
    "        h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "        \n",
    "        print(\"fc2 : \",h_fc2)\n",
    "        \n",
    "    with tf.variable_scope(\"logit\"):\n",
    "        W_fc3 = weight_variable([192, FLAGS.num_classes])\n",
    "        b_fc3 = bias_variable([FLAGS.num_classes])\n",
    "        logit = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "        \n",
    "        print(\"logit : \",logit)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input :  Tensor(\"Input-queue/shuffle_batch:0\", shape=(128, 32, 32, 3), dtype=float32)\n",
      "conv 1 :  Tensor(\"conv1/Relu:0\", shape=(128, 32, 32, 64), dtype=float32)\n",
      "pool 1 :  Tensor(\"maxpool1/MaxPool:0\", shape=(128, 16, 16, 64), dtype=float32)\n",
      "conv 2 :  Tensor(\"conv2/Relu:0\", shape=(128, 16, 16, 64), dtype=float32)\n",
      "pool 2 :  Tensor(\"maxpool2/MaxPool:0\", shape=(128, 8, 8, 64), dtype=float32)\n",
      "flatten :  Tensor(\"Flatten/Reshape:0\", shape=(128, 4096), dtype=float32)\n",
      "fc1 :  Tensor(\"fc1/Relu:0\", shape=(128, 384), dtype=float32)\n",
      "fc2 :  Tensor(\"fc2/Relu:0\", shape=(128, 192), dtype=float32)\n",
      "logit :  Tensor(\"logit/Relu:0\", shape=(128, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Logits:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.variable_scope(\"Input-queue\"):\n",
    "    images,labels = distorted_inputs(FLAGS.data_dir,FLAGS.batch_size,distort=False)\n",
    "    tf.summary.image('images', images)\n",
    "    \n",
    "logit = inference(images)\n",
    "tf.summary.histogram(\"Logits\",logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = run_tf(logit)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logit,lables):\n",
    "    \n",
    "    with tf.variable_scope(\"cross-entropy\"):\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.reshape(labels,[FLAGS.batch_size]), logits=logit)\n",
    "        avg_cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "        return avg_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DECAYING LEARNING RATE**\n",
    "\n",
    "**tf.train.exponential_decay**\n",
    "\n",
    "Reduces learning rate exponentially every **decay_steps**\n",
    "\n",
    "decayed_learning_rate = learning_rate X decay_rate ^ (global_step / decay_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007943282"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = tf.train.exponential_decay(learning_rate=0.01,global_step=10,decay_steps=100,decay_rate=0.1)\n",
    "tf.Session().run(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = tf.train.exponential_decay(0.01,100,100,0.1)\n",
    "tf.Session().run(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000100000005"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = tf.train.exponential_decay(0.01,200,100,0.1)\n",
    "tf.Session().run(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = []\n",
    "for i in range(1000):\n",
    "    e.append(tf.train.exponential_decay(0.1,i,400,0.01,staircase=True))\n",
    "e_lr = tf.Session().run(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f839ed1ee10>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83fd4ab390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(e_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mean_cross_entropy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = tf.placeholder(FLAGS.dtype)\n",
    "decay_step = tf.placeholder(tf.int32)\n",
    "decay_rate = tf.placeholder(FLAGS.dtype)\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "total_loss = loss(logit,labels)\n",
    "tf.summary.scalar(\"mean_cross_entropy\",total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.train.exponential_decay(\n",
    "                                learning_rate=learning_rate,\n",
    "                                global_step=global_step,\n",
    "                                decay_steps=decay_step,\n",
    "                                decay_rate=decay_rate,\n",
    "                                staircase=True)\n",
    "tf.summary.scalar(\"learning_rate\",lr)\n",
    "opt = tf.train.GradientDescentOptimizer(lr)\n",
    "#opt = tf.train.AdamOptimizer(lr)\n",
    "grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "grad_to_compute = [[g,v] for g,v in grads if g is not None]\n",
    "# for grad,var in grad_to_compute:\n",
    "#     tf.summary.histogram(\"Params/\" + var.name,var)\n",
    "#     tf.summary.histogram(\"Gradients/\" + var.name,grad)\n",
    "    \n",
    "train_op = opt.apply_gradients(grads, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {learning_rate:0.01,\n",
    "            decay_rate : 0.1,\n",
    "            decay_step:80000}\n",
    "\n",
    "max_steps = 1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Loss :  5.75e+00\n",
      "100 Loss :  2.21e+00\n",
      "200 Loss :  2.21e+00\n",
      "300 Loss :  2.18e+00\n",
      "400 Loss :  2.24e+00\n",
      "500 Loss :  2.23e+00\n",
      "600 Loss :  2.24e+00\n",
      "700 Loss :  2.13e+00\n",
      "800 Loss :  2.21e+00\n",
      "900 Loss :  2.22e+00\n",
      "1000 Loss :  2.07e+00\n",
      "1100 Loss :  1.99e+00\n",
      "1200 Loss :  2.11e+00\n",
      "1300 Loss :  2.13e+00\n",
      "1400 Loss :  2.14e+00\n",
      "1500 Loss :  2.16e+00\n",
      "1600 Loss :  2.05e+00\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(config=config) as sess: \n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"log/Train_random_init/t1_SGD_lr0.01\",sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        _,loss,out,summary = sess.run([train_op,total_loss,logit,merged],feed_dict=feed_dict)\n",
    "        writer.add_summary(summary,i)\n",
    "        if(i%100 == 0):\n",
    "            print(i, \"Loss : \", \"{:.2e}\".format(loss))\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tf(tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, 0, 1, 1, 7, 1, 9, 1, 4, 3, 1, 6, 5, 9, 1, 4, 0, 2, 5, 9,\n",
       "       5, 6, 0, 5, 1, 1, 6, 2, 0, 2, 1, 5, 0, 4, 0, 7, 3, 0, 5, 6, 9, 2,\n",
       "       5, 4, 9, 6, 6, 4, 3, 7, 0, 1, 0, 4, 3, 2, 7, 1, 5, 1, 2, 3, 8, 5,\n",
       "       3, 5, 7, 2, 2, 4, 5, 5, 9, 4, 2, 2, 4, 8, 3, 8, 6, 9, 6, 9, 5, 2,\n",
       "       1, 8, 7, 0, 1, 9, 1, 5, 4, 8, 5, 5, 3, 7, 1, 5, 2, 9, 3, 1, 5, 5,\n",
       "       5, 0, 0, 3, 9, 5, 8, 6, 6, 6, 0, 7, 4, 3, 8, 9, 9, 5], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tf(tf.reshape(labels,[FLAGS.batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_to_compute = [[g,v] for g,v in grads if g is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/Weights:0\n",
      "conv1/biases:0\n",
      "conv2/Weights:0\n",
      "conv2/biases:0\n",
      "fc1/Weights:0\n",
      "fc1/biases:0\n",
      "fc2/Weights:0\n",
      "fc2/biases:0\n",
      "logit/Weights:0\n",
      "logit/biases:0\n"
     ]
    }
   ],
   "source": [
    "for g,v in grad_to_compute:\n",
    "    print(v.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
